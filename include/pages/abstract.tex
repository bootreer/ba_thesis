\chapter{Abstract}
Today's SSDs are capable of performing millions of I/O operations per second (IOPS). However, while capable, traditional Linux I/O APIs and even newer asynchronous APIs often fall short of achieving the lowest possible latency and highest throughput due to their dependence on kernel-based I/O paths, which introduce significant overheads. The Storage Performance Development Kit (SPDK) offers a solution through its user space driver model, eliminating this overhead, but at the cost of increased complexity and potential safety concerns due to its C codebase.

Recognising these challenges, we present a novel user space driver written in Rust, a language that promises memory safety without sacrificing performance, employing zero-copy I/O and simple abstractions, enabling an easier way to assess individual NVMe features and I/O path optimisations. We show that, despite the stripped-down design of the driver, we achieve SPDK-like throughput and latency. Our work undertakes a comparative analysis between vroom, our proposed NVMe driver, and SPDK, as well as the Linux I/O APIs, intending to simplify access to high-performance storage technologies.
