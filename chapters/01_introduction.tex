\chapter{Introduction}\label{chapter:introduction}
In the age of PCIe Gen 5.0 NVMe SSDs, we have storage devices which are capable of exceeding one million I/O operations per second (IOPS). However, with Linux's standard file I/O API ($\texttt{p}$)$\texttt{read}$ and ($\texttt{p}$)$\texttt{write}$, achieving this level of throughput not possible, requiring over 100 threads to ``get good throughput on a modern SSD'' \cite{haas2020exploiting}. Modern asynchronous I/O libraries, such as $\texttt{libaio}$ and $\texttt{io\_uring}$, have offered improvements by diminishing the kernel gap, thus reaching closer to the physical limits of the SSD, but these still pay performance penalties by interacting the operating system kernel, like context switching and interrupt handling \cite{storage_api}. Maximising the throughput of an SSD requires circumventing the kernel entirely, which has led to the adoption of user-space drivers such as SPDK's NVMe driver.

With this in mind, why write our own driver when SPDK exists? The SPDK codebase itself is complex and extensive, posing a barrier of entry into understanding its inner workings as well as understanding how to optimise storage I/O paths, with SPDK's $\texttt{hello\_world.c}$\footnote{\url{https://github.com/spdk/spdk/blob/0680c7a27bd3950f0b7abb21effde66d5da7976e/examples/nvme/hello_world/hello_world.c}} example coming in at 511 lines. It is also written in C, a language where critical errors, such as memory leaks or segmentation faults are easily created in a lapse of judgement. While C remains the language used for the Linux kernel, it isn't necessarily the ideal language for driver development. In 2017, Cutler et al. analysed bugs in the Linux kernel which enabled arbitrary code execution and found out of 65, 40 bugs stemmed from invalid memory accesses, such as use-after-frees \cite{cutler}; it was found that 39 of these bugs stemmed from device drivers \cite{driver_lang}.

In this thesis we posit that it is feasible to develop a driver that achieves comparable performance to SPDK, with a simplified API and less code, while leveraging the benefits of a memory-safe programming language. Thus we want to offer a platform which simplifies the exploration of NVMe and SSD capabilities, as well as create a driver where unsafe code is kept to a minimum. To this end, we will explore the development and evaluation of a user-space storage driver written in Rust, a language that promises memory safety guarantees without any performance downfalls.

In \autoref{chapter:basics} we will go over all the relevant background information, having a look at how communicating with PCIe devices works, the NVMe specification, and the Rust programming language. Then, we will shortly elaborate on some other relevant I/O APIs and NVMe driver implementations in \autoref{chapter:related}.
We present the implementation in \autoref{chapter:implementation}. We go over the architecture of the driver, as well as driver specific implementations, after which we show how I/O operations are handled.

Finally, we analyse the performance of the driver itself in \autoref{chapter:eval}, looking at its throughput and latency, while also comparing it to SPDK and the aforementioned Linux I/O APIs.
